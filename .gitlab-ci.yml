stages:
  - build
  - test
  - deploy
  - transform

variables:
  APP_IMAGE: "$CI_REGISTRY_IMAGE/ecom-app"
  DBT_PROJECT_DIR: "dbt"
  K8S_DIR: "airflow-k8-dbt/k8s/airflow"

# ---------- BUILD STAGE ----------
build_app:
  stage: build
  image: docker:24.0.7
  services:
    - docker:24.0.7-dind
  variables:
    DOCKER_DRIVER: overlay2
  script:
    - echo "Logging into container registry..."
    - docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" "$CI_REGISTRY"
    - echo "Building application image..."
    - docker build -t "$APP_IMAGE:$CI_COMMIT_SHORT_SHA" .
    - docker tag "$APP_IMAGE:$CI_COMMIT_SHORT_SHA" "$APP_IMAGE:latest"
    - docker push "$APP_IMAGE:$CI_COMMIT_SHORT_SHA"
    - docker push "$APP_IMAGE:latest"
  only:
    - main
    - master

# ---------- TEST STAGE (DBT TEST) ----------
dbt_test:
  stage: test
  image: python:3.12-slim
  before_script:
    - pip install --no-cache-dir dbt-core dbt-mysql
    - cd "$DBT_PROJECT_DIR"
    # Write profiles.yml from env vars for CI
    - mkdir -p ~/.dbt
    - cat profiles_example.yml | sed "s/{{ env_var('DBT_MYSQL_USER') }}/$DBT_MYSQL_USER/; s/{{ env_var('DBT_MYSQL_PASSWORD') }}/$DBT_MYSQL_PASSWORD/" > ~/.dbt/profiles.yml
  script:
    - dbt deps
    - dbt test
  only:
    - main
    - master

# ---------- DEPLOY STAGE (K8S + HELM) ----------
deploy_to_minikube:
  stage: deploy
  image: alpine/helm:3.15.0
  variables:
    KUBECONFIG: "/builds/$CI_PROJECT_PATH/.kube/config"
  before_script:
    - apk add --no-cache curl bash
    - mkdir -p "$(dirname "$KUBECONFIG")"
    # If you store kubeconfig as base64 CI variable:
    # echo "$KUBECONFIG_CONTENT" | base64 -d > "$KUBECONFIG"
  script:
    - echo "Using kube context:"
    - kubectl config get-contexts || true
    - cd "$K8S_DIR"
    - echo "Applying MySQL manifest..."
    - kubectl apply -f mysql/mysql-deployment.yaml
    - echo "Deploying / upgrading Airflow via Helm..."
    - helm repo add apache-airflow https://airflow.apache.org || true
    - helm repo update apache-airflow
    - helm upgrade --install airflow apache-airflow/airflow \
        --namespace airflow \
        --create-namespace \
        -f helm/values-mysql.yaml
    - kubectl get pods -n airflow
  environment:
    name: dev
  only:
    - main
    - master
  when: manual   # optional: make deploy manual

# ---------- TRANSFORM STAGE (DBT RUN + DOCS) ----------
dbt_run_and_docs:
  stage: transform
  image: python:3.12-slim
  before_script:
    - pip install --no-cache-dir dbt-core dbt-mysql
    - cd "$DBT_PROJECT_DIR"
    - mkdir -p ~/.dbt
    - cat profiles_example.yml | sed "s/{{ env_var('DBT_MYSQL_USER') }}/$DBT_MYSQL_USER/; s/{{ env_var('DBT_MYSQL_PASSWORD') }}/$DBT_MYSQL_PASSWORD/" > ~/.dbt/profiles.yml
  script:
    - dbt deps
    - dbt run
    - dbt docs generate
  artifacts:
    paths:
      - dbt/target
    when: always
    expire_in: 1 week
  only:
    - main
    - master
  needs:
    - job: dbt_test
      artifacts: false
