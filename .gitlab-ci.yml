stages:
  - build
  - test
  - deploy
  - transform

variables:
  DOCKER_DRIVER: overlay2

# ---------- BUILD STAGE ----------
build_app_image:
  stage: build
  tags: ["minikube", "docker"]    # must match your runner tags
  image: docker:latest
  services:
    - docker:dind
  variables:
    DOCKER_TLS_CERTDIR: ""
  script:
    - docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" "$CI_REGISTRY"
    - docker build -t "$CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA" .
    - docker push "$CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA"
  only:
    - main
    - merge_requests

# ---------- TEST STAGE (dbt test) ----------
dbt_test:
  stage: test
  tags: ["minikube", "docker"]
  image: ghcr.io/dbt-labs/dbt-mysql:1.8.0
  variables:
    DBT_PROFILES_DIR: "$CI_PROJECT_DIR/dbt/profiles"
  script:
    - cd dbt
    - dbt deps
    - dbt test
  only:
    - main
    - merge_requests

# ---------- DEPLOY STAGE (k8s deploy) ----------
deploy_app:
  stage: deploy
  tags: ["minikube", "docker"]
  image: alpine/helm:3.14.0
  before_script:
    - apk add --no-cache curl bash kubectl
    # Recreate kubeconfig from CI variable
    - echo "$KUBECONFIG_CONTENT" | base64 -d > kubeconfig
    - export KUBECONFIG="$PWD/kubeconfig"
  script:
    # Optional: see cluster
    - kubectl config view
    - kubectl get nodes

    # Namespace
    - kubectl get ns airflow || kubectl create namespace airflow

    # Apply MySQL manifest
    - kubectl apply -f airflow-k8-dbt/k8s/airflow/mysql/mysql-deployment.yaml

    # Wait for MySQL
    - kubectl wait --namespace airflow \
        --for=condition=ready pod \
        -l app=airflow-mysql \
        --timeout=180s

    # Add Airflow Helm repo, deploy Airflow using your values-mysql.yaml
    - helm repo add apache-airflow https://airflow.apache.org || true
    - helm repo update apache-airflow
    - helm upgrade --install airflow apache-airflow/airflow \
        --namespace airflow \
        -f airflow-k8-dbt/k8s/airflow/helm/values-mysql.yaml \
        --create-namespace \
        --debug

    - kubectl get pods -n airflow
  needs:
    - build_app_image
  only:
    - main

# ---------- TRANSFORM STAGE ----------
dbt_run:
  stage: transform
  tags: ["minikube", "docker"]
  image: ghcr.io/dbt-labs/dbt-mysql:1.8.0
  variables:
    DBT_PROFILES_DIR: "$CI_PROJECT_DIR/dbt/profiles"
  script:
    - cd dbt
    - dbt deps
    - dbt run
  needs:
    - dbt_test
  only:
    - main

dbt_docs:
  stage: transform
  tags: ["minikube", "docker"]
  image: ghcr.io/dbt-labs/dbt-mysql:1.8.0
  variables:
    DBT_PROFILES_DIR: "$CI_PROJECT_DIR/dbt/profiles"
  script:
    - cd dbt
    - dbt deps
    - dbt docs generate
  needs:
    - dbt_run
  artifacts:
    paths:
      - dbt/target
  only:
    - main
